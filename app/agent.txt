# # app/agent.py

# app/agent.py

from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.runnables import RunnableMap
from langchain_core.runnables import RunnableLambda
from langchain_core.runnables import RunnableSequence

#from langchain_openai import ChatOpenAI
from openrouter import ChatOpenRouter

from  retriever import get_retriever

import os
from dotenv import load_dotenv

load_dotenv()

# Load API key
openai_api_key = os.getenv("OPENAI_API_KEY")



# Define prompt
prompt = PromptTemplate.from_template("""
You are TechMart's friendly assistant seller. Use the following context to answer customer questions about products, pricing, and availability.

Context:
{context}

Question:
{question}

Answer as a helpful, conversational assistant.
""")

# Build the agent
def build_agent():
    retriever = get_retriever()
    llm = ChatOpenRouter(
    base_url="https://openrouter.ai/api/v1",
    api_key=os.getenv("OPENROUTER_API_KEY"),
    default_headers={
        "HTTP-Referer": "https://techmart.ai",  # Use your site or project name
        "X-Title": "TechMart Assistant"
    }
)


    #llm = ChatOpenAI(api_key=openai_api_key)

    # RAG pipeline using RunnableSequence
    rag_chain = (
        RunnableMap({"context": retriever, "question": RunnablePassthrough()})
        | prompt
        | llm
    )

    return rag_chain

# from langchain_core.prompts import PromptTemplate
# from langchain_community.chains import RetrievalQA
# from langchain_community.vectorstores import FAISS
# from langchain.embeddings import HuggingFaceEmbeddings
# from langchain_openai import OpenAI  # if you're using OpenAI
# import os
# from dotenv import load_dotenv

# load_dotenv()

# # Load API key
# openai_api_key = os.getenv("OPENAI_API_KEY")

# # Define agent personality and prompt
# prompt_template = PromptTemplate(
#     input_variables=["context", "question"],
#     template="""
# You are TechMart's friendly assistant seller. Use the following context to answer customer questions about products, pricing, and availability.

# Context:
# {context}

# Question:
# {question}

# Answer as a helpful, conversational assistant.
# """
# )

# # Placeholder for retriever setup (to be implemented)
# def get_retriever():
#     # Load CSV or connect to MySQL, embed, and return retriever
#     pass

# # Build the RAG pipeline
# def build_agent():
#     retriever = get_retriever()
#     llm = OpenAI(openai_api_key=openai_api_key)
#     qa_chain = RetrievalQA.from_chain_type(
#         llm=llm,
#         retriever=retriever,
#         chain_type_kwargs={"prompt": prompt_template}
#     )
#     return qa_chain